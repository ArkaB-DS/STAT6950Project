<<<<<<< HEAD
---
title: "Analysis3"
author: "Arkajyoti Bhattacharjee"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Read and create databases for analysis

```{r echo = TRUE,eval = FALSE}
database <- read.table("database.csv", header = TRUE, sep = ",")
library(tidyverse)
database <- database %>%
  mutate(RGDP2019 = (GDP2019-GDP2018)/GDP2018)
db19 <- database %>%
  select(matches('country|2019')) # add RGDP, rate of change in GDP from 2018-2019
db19 <- select(db19, -GDP2019) # drop GDP2019 
# formatting NFCR column
db19[, "NFCR2019"] <- sapply(db19[,"NFCR2019"], function (x) gsub('%', '', x))
db19[,"NFCR2019"] <- as.numeric(db19[,"NFCR2019"])
#check the number of NAs per column
apply(is.na(db19), 2, sum)
```
# Exploratory Data Analysis

```{r echo = TRUE, eval = TRUE, warning=FALSE}
library(GGally)

## FULL SCATTERPLOT MATRIX TOO SPACIOUS
# ggpairs(db19[, -1], progress = FALSE, 
#         columnLabels = c("NFCR", "CPI", "AML", "ARR", "WES", "GE", "PV", "RQ", 
#                          "RL", "VA", "RGDP")) 

# From the scatterplot matrix, we see that RL and CPI have a high correlation (0.902), along with GE & RL (0.943), GE & RQ (0.9370), and RQ & RL (0.929).
## indicative of multicollinearity
# The distribution of NFCR seems to be heavy-tailed.
# log transforms??
# all are continuous variables
# predictors don't seem to be related to the response much
# We drop RL, RQ(why?--common to CPI, RQ, & GE, Y IS RELATED MORE TO CPI AND GE,
# RQ AND GE ARE SIMILAR INTUTITIVELY)
# EXPLAIN HOW THE RELATIONSHIP IS INTUITIVE?!

## RATHER THAN DOING SCATTERPLOT MATRIX, DO A HEAT MAP FOR SIZE CONSTRAINT OFCOURSE

cor.mat <- round(cor(na.omit(db19[, -1])),3)
library(reshape2)
cor.mat[lower.tri(cor.mat)] <- NA
melted.cor.mat <- melt(cor.mat)

pdf("images/cormatheat.pdf")
ggplot(data = melted.cor.mat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
 scale_fill_viridis_c(option = "turbo", na.value = "white" ,
   limit = c(-1,1), space = "Lab", 
   name="Pearson\nCorrelation") +
  theme_minimal()+ 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.6, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))
dev.off()

pdf("images/scatterplotDropping2.pdf")
ggpairs(db19[, -c(1, 7, 10)], progress = FALSE, 
        columnLabels = c("NFCR", "CPI", "AML", "ARR", "WES", "PV", "RQ", 
                         "VA", "RGDP"),
        axisLabels = "none")
dev.off()
# OTHER SUMMARY PLOTS
subdb19 <- select(db19, c(GE2019, PV2019, RQ2019, RL2019, VA2019))
#install.packages("reshape2")
library(reshape2)
melted.data <- melt(subdb19)
#View(melted.data)
p1 <- ggplot(data = melted.data, aes(x=variable, y=value))+
  geom_boxplot(aes(fill = variable)) + #violin plot 
  labs(
    x= "Governance Quality"
  )

pdf("images/GQs.pdf")
p1
dev.off()


p2 <- ggplot(data = db19, aes(x=NFCR2019))+
  geom_histogram(aes(y=..density..), fill = "magenta")+
  geom_density(color="red")
p3 <- ggplot(data = db19, aes(x=CPI2019))+
  geom_histogram(aes(y=..density..), fill = "seagreen")+
  geom_density(color="red")
p4 <- ggplot(data = db19, aes(x=AML2019))+
  geom_histogram(aes(y=..density..), fill = "orange")+
  geom_density(color="red")
p5 <- ggplot(data = db19, aes(x=ARR2019))+
  geom_histogram(aes(y=..density..), fill = "blue")+
  geom_density(color="red")+
  theme(axis.text.x = element_blank())
p6 <- ggplot(data = db19, aes(x=RGDP2019))+
  geom_histogram(aes(y=..density..), fill = "purple")+
  geom_density(color="red")
p7 <- ggplot(data = db19, aes(x=WES2019))+
  geom_histogram(aes(y=..density..), fill = "cyan")+
  geom_density(color="red")

# install.packages("patchwork")
library(patchwork)
pdf("images/hists.pdf")
(p2 +p3+p4)/(p6 + p5 +p7)
dev.off()
```

# Methods and Model Building

## Naive Model

```{r echo =TRUE, eval =TRUE}
model.naive <- lm(NFCR2019~CPI2019+AML2019+log(ARR2019)+WES2019+GE2019+PV2019+RQ2019+
                    RL2019+VA2019+RGDP2019, data=db19)
library(car)
vif(model.naive)
summary(model.naive)

model.naive2 <- lm(NFCR2019~CPI2019+AML2019+log(ARR2019)+WES2019+GE2019+PV2019+RQ2019+
                    VA2019+RGDP2019, data=db19)
vif(model.naive2)
summary(model.naive2)

model.naive3 <- lm(NFCR2019~CPI2019+AML2019+log(ARR2019)+WES2019+PV2019+RQ2019+VA2019+
                    RGDP2019, data=db19)
vif(model.naive3)
summary(model.naive3)
```
## Transformation of Predictors

```{r echo = TRUE, EVAL = TRUE}
library(car)
summary(powerTransform(cbind(CPI2019, AML2019, log(ARR2019),  WES2019,
                             PV2019, RQ2019,VA2019, RGDP2019)~1, data = db19,
                       family = 'yjPower'))
mod1 <- lm(NFCR2019~sqrt(CPI2019)+AML2019+log(ARR2019)+  WES2019+
                             PV2019+RQ2019+ VA2019+ RGDP2019, data=db19)

vif(mod1)
summary(mod1)

## EXPLORING ALL SUGGESTED TRANSFORMATIONS--NOT INTERPRETABLE

modx <- lm(NFCR2019~sqrt(CPI2019)+AML2019+log(ARR2019)+  WES2019+
                             I(PV2019^1.33)+RQ2019+ I(VA2019^2)+ RGDP2019, data=db19)
vif(modx)
summary(modx)
```
## Variable Selection

```{r echo = TRUE, EVAL = TRUE}
library(leaps)
(summary_best_subset1<-summary(regsubsets(NFCR2019~yeo.johnson(CPI2019,0.5)+
                                            yeo.johnson(ARR2019,0)+  WES2019+
                             PV2019+RQ2019+ VA2019+ RGDP2019, data=na.omit(db19))))
which.max(summary_best_subset1$adjr2)
## keep log(ARR), WES, PV (note correlated with CPI), VA(note correalted with RQ), RGDP (my choice)
(summary_best_subsetx<-summary(regsubsets(NFCR2019~yeo.johnson(CPI2019,0.5)+
                                            yeo.johnson(ARR2019,0)+  WES2019+
                             yeo.johnson(PV2019,1.33)+RQ2019+ yeo.johnson(VA2019,2)+ RGDP2019, data=na.omit(db19))))
which.max(summary_best_subsetx$adjr2)
## keep log(ARR), WES, PV (note correlated with CPI), VA(note correlated with RQ), RGDP (my choice)

## ARR, WES PV VA
## ARR WES PV RQ modx

## EXPLORING ADJUSTED R^2 FOR DIFFERNET VARIABLE SELECTION MODELS
modx2 <- lm(NFCR2019~log(ARR2019)+  WES2019+
                             I(PV2019^1.33)+RQ2019+ RGDP2019, data=db19)
modx3 <- lm(NFCR2019~log(ARR2019)+  WES2019+
                             PV2019+RQ2019+ RGDP2019, data=db19)
mod12 <- lm(NFCR2019~log(ARR2019)+  WES2019+
                             PV2019+VA2019+ RGDP2019, data=db19)
mod13 <- lm(NFCR2019~log(ARR2019)+  WES2019+
                             PV2019+VA2019, data=db19)
summary(modx2)$adj.r.squared
summary(modx3)$adj.r.squared
summary(mod12)$adj.r.squared # highest
summary(mod13)$adj.r.squared
```
## Transformation of response
```{r echo = TRUE,eval = TRUE}
summary(powerTransform(lm(NFCR2019~yeo.johnson(ARR2019, 0) + WES2019 + 
                            PV2019 + VA2019 + RGDP2019, 
                          data = na.omit(db19)),
                       family = 'yjPower'))
##y^1.61

## NOT INTERPRETABLE -- SO IGNORE
```

```{r echo  =TRUE, eval = TRUE}
NFCR<-yeo.johnson(na.omit(db19)[,"NFCR2019"], 1.61)
ARR<-yeo.johnson(na.omit(db19)[,"ARR2019"], 0)
mod2<-lm(NFCR~ARR+WES2019+PV2019+VA2019+RGDP2019, data = na.omit(db19))
summary(mod2)
vif(mod2)
mod3<-lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = na.omit(db19))
summary(mod3)
vif(mod3)

##mod 3 more interpretable and has higher adj R^2
```

## Regression Diagnostics

### Outlier analysis

```{r echo = TRUE, eval = TRUE}
plot(cooks.distance(mod3),type="b",pch=18,col="red")
cutoff = 4*mean(cooks.distance(mod3))
abline(h=cutoff,lty=2)
which(cooks.distance(mod3)>cutoff)

db19woOut <- na.omit(db19)[-c(17,24,36,47,51,60,73),]
db19woOut <- db19woOut[-c(8, 69, 96),]
db19woOut <- db19woOut[-c(11),]
ARR<-yeo.johnson(db19woOut[,"ARR2019"], 0)
mod4<- lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut)

plot(cooks.distance(mod4),type="b",pch=18,col="red")
cutoff = 4*mean(cooks.distance(mod3))
abline(h=cutoff,lty=2)
which(cooks.distance(mod4)>cutoff)

which(hatvalues(mod3)>2*mod3$rank/length(hatvalues(mod3)))
db19woOut2 <- na.omit(db19)[-c(3,21, 31,74,88,99,100,107),]
db19woOut2 <- db19woOut2[-c(3, 41, 67, 97),]
db19woOut2 <- db19woOut2[-c(55),]
db19woOut2 <- db19woOut2[-c(94),]
db19woOut2 <- db19woOut2[-c(21, 46, 66),]
db19woOut2 <- db19woOut2[-c(15, 31, 41, 65),]
ARR<-yeo.johnson(db19woOut2[,"ARR2019"], 0)
mod5<- lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut2)
ncvTest(mod5)
which(hatvalues(mod5)>2*mod5$rank/length(hatvalues(mod5)))




which(abs(rstandard(mod3))>3)
# 24 51 73 
db19woOut3 <- na.omit(db19)[-c(24, 51, 73),]
ARR<-yeo.johnson(db19woOut3[,"ARR2019"], 0)
mod6<- lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut3)
ncvTest(mod6)
which(abs(rstandard(mod6))>3)

db19woOut3 <- db19woOut3[-c(17,35,46),]
ARR<-yeo.johnson(db19woOut3[,"ARR2019"], 0)
mod6<- lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut3)
ncvTest(mod6)
which(abs(rstandard(mod6))>3)

db19woOut3 <- db19woOut3[-c(70),]
ARR<-yeo.johnson(db19woOut3[,"ARR2019"], 0)
mod6<- lm(yeo.johnson(NFCR2019,0)~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut3)
ncvTest(mod6)
which(abs(rstandard(mod6))>3)

plev1 <- ggplot(data.frame(x=1:length(hatvalues(mod3)),y = hatvalues(mod3)),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Leverage"
  )+
  geom_hline(yintercept = 3*mod3$rank/length(hatvalues(mod3)),
             color = "red", linetype = "dashed")

# pcook1 <- ggplot(data.frame(x=1:length(cooks.distance(mod3)),y = cooks.distance(mod3)),
#                         aes(x=x, y=y))+
#   geom_point()+
#  geom_line(color = "blue")+
#   labs(
#     x = "Data point",
#     y = "Cook's Distance"
#   )+
#   geom_hline(yintercept = 0.5,
#              color = "red", linetype = "dashed")
prstud1 <- ggplot(data.frame(x=1:length(rstudent(mod3)),y = abs(rstudent(mod3))),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Absolute Studentized Residuals"
  )+
  geom_hline(yintercept = 3,
             color = "red", linetype = "dashed")


plev2 <- ggplot(data.frame(x=1:length(hatvalues(mod4)),y = hatvalues(mod4)),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Leverage"
  )+
  geom_hline(yintercept = 3*mod4$rank/length(hatvalues(mod4)),
             color = "red", linetype = "dashed")

# pcook2 <- ggplot(data.frame(x=1:length(cooks.distance(mod4)),y = cooks.distance(mod4)),
#                         aes(x=x, y=y))+
#   geom_point()+
#  geom_line(color = "blue")+
#   labs(
#     x = "Data point",
#     y = "Cook's Distance"
#   )+
#   geom_hline(yintercept = 2*mean(cooks.distance(mod4)),
#              color = "red", linetype = "dashed")
prstud2 <- ggplot(data.frame(x=1:length(rstudent(mod4)),y = abs(rstudent(mod4))),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Absolute Studentized Residuals"
  )+
  geom_hline(yintercept = 3,
             color = "red", linetype = "dashed")

library(patchwork)
pdf("images/outlier.pdf")
(plev1+plev2)/(prstud1+prstud2)
dev.off()
```

### Test for homoscedasticity

```{r echo  = TRUE, eval = TRUE}
pdf("images/homopara.pdf")
ggplot(data.frame(x=fitted(mod4), y = rstandard(mod4)), aes(x=x,y = y))+
  geom_point(color = "blue" )+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(
    x = "Fitted Values",
    y = "Standardized Residuals",
  )
dev.off()
ncvTest(mod4)
```

### Test for normality

```{r echo  = TRUE, eval = TRUE}
shapiro.test(resid(mod4))
pqq<-ggplot(data.frame(y=rstandard(mod4)), aes(sample = y))+
  stat_qq(color="blue")+
  stat_qq_line(color="red")+
  labs(
    x="Theoretical Quantiles",
    y="Standardized Residuals"
  )
pdf("images/qqplot.pdf")
pqq
dev.off()
```

### Multicollinearity

```{r echo = TRUE, eval = TRUE}
library(car)
vif(mod4)
```


# Alternating Conditional Expectation

## ACE Algorithm

```{r echo = TRUE,eval = TRUE}
#install.packages("acepack")
library(acepack)
db19noNA <- na.omit(db19)
ACE <- ace(y = db19noNA[, 2], x = as.matrix(db19noNA[, -c(1, 2)]))
ACEdf<-cbind.data.frame(NFCR2019=ACE$ty, ACE$tx) 
model.ace <- lm(NFCR2019~., data = ACEdf)
summary(model.ace)


library(ggplot2)
p1 <- ggplot(data = data.frame(ACE$y, ACE$ty), aes(x=ACE$y, y = ACE$ty)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "NFCR2019",
    y = "Transformed"
  )
p2 <- ggplot(data = data.frame(x=ACE$x[1, ], y=ACE$tx[, 1]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "CPI2019",
    y = "Transformed"
  )
p3 <- ggplot(data = data.frame(x=ACE$x[2, ], y=ACE$tx[, 2]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "AML2019",
    y = "Transformed"
  )
p4 <- ggplot(data = data.frame(x=ACE$x[3, ], y=ACE$tx[, 3]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "ARR2019",
    y = "Transformed"
  )
p5 <- ggplot(data = data.frame(x=ACE$x[4, ], y=ACE$tx[, 4]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "WES2019",
    y = "Transformed"
  )
p6 <- ggplot(data = data.frame(x=ACE$x[5, ], y=ACE$tx[, 5]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "GE2019",
    y = "Transformed"
  )
p7 <- ggplot(data = data.frame(x=ACE$x[6, ], y=ACE$tx[, 6]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "PV2019",
    y = "Transformed"
  )
p8 <- ggplot(data = data.frame(x=ACE$x[7, ], y=ACE$tx[, 7]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "RQ2019",
    y = "Transformed"
  )
p9 <- ggplot(data = data.frame(x=ACE$x[8, ], y=ACE$tx[, 8]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "RL2019",
    y = "Transformed"
  )
p10 <- ggplot(data = data.frame(x=ACE$x[9, ], y=ACE$tx[, 9]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "VA2019",
    y = "Transformed"
  )
p11 <- ggplot(data = data.frame(x=ACE$x[10, ], y=ACE$tx[, 10]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "RGDP2019",
    y = "Transformed"
  )
```

## Regression Diagnostics

### Outlier analysis

```{r echo = TRUE, eval = TRUE}
db19noNA <- na.omit(db19)
ACE <- ace(y = db19noNA[, 2], x = as.matrix(db19noNA[, -c(1, 2)]))
ACEdf<-cbind.data.frame(NFCR2019=ACE$ty, ACE$tx) 
model.ace <- lm(NFCR2019~., data = ACEdf)


plot(cooks.distance(model.ace),type="b",pch=18,col="red")
cutoff = 4*mean(cooks.distance(model.ace))
abline(h=cutoff,lty=2)
plot(abs(hatvalues(model.ace)), type= "b")
abline(h=3*model.ace$rank/length(hatvalues(model.ace)))
plot(abs(rstandard(model.ace)), type= "b")
abline(h=3)

which(cooks.distance(model.ace)>cutoff)
which(abs(hatvalues(model.ace))>3*model.ace$rank/length(hatvalues(model.ace)))
which(abs(rstandard(model.ace))>3)


ncvTest(model.ace)

db19noNA <- db19noNA[-c(44,49),]
db19noNA <- db19noNA[-c(17),]
db19noNA <- db19noNA[-c(17),]
db19noNA <- db19noNA[-c(69),]
db19noNA <- db19noNA[-c(102),]
db19noNA <- db19noNA[-c(102),]
db19noNA <- db19noNA[-c(83),]
db19noNA <- db19noNA[-c(54),]
db19noNA <- db19noNA[-c(30),]
db19noNA <- db19noNA[-c(54),]

ACE <- ace(y = db19noNA[, 2], x = as.matrix(db19noNA[, -c(1, 2)]))
ACEdf<-cbind.data.frame(NFCR2019=ACE$ty, ACE$tx) 
model.ace <- lm(NFCR2019~., data = ACEdf)
summary(model.ace)$adj.r.squared

plev3 <- ggplot(data.frame(x=1:length(hatvalues(model.ace)),y = hatvalues(model.ace)),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Leverage"
  )+
  geom_hline(yintercept = 3*model.ace$rank/length(hatvalues(model.ace)),
             color = "red", linetype = "dashed")

prstud3 <- ggplot(data.frame(x=1:length(rstudent(model.ace)),y = abs(rstudent(model.ace))),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Absolute Studentized Residuals"
  )+
  geom_hline(yintercept = 3,
             color = "red", linetype = "dashed")


plev4 <- ggplot(data.frame(x=1:length(hatvalues(model.ace)),y = hatvalues(model.ace)),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Leverage"
  )+
  geom_hline(yintercept = 3*mod4$rank/length(hatvalues(mod4)),
             color = "red", linetype = "dashed")

prstud4 <- ggplot(data.frame(x=1:length(rstudent(model.ace)),y = abs(rstudent(model.ace))),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Absolute Studentized Residuals"
  )+
  geom_hline(yintercept = 3,
             color = "red", linetype = "dashed")

library(patchwork)
pdf("images/outliernp.pdf")
(plev3+plev4)/(prstud3+prstud4)
dev.off()
```

### Test for homoscedasticity

```{r echo  = TRUE, eval = TRUE}
pdf("images/homoparanp.pdf")
ggplot(data.frame(x=fitted(model.ace), y = rstandard(model.ace)), aes(x=x,y = y))+
  geom_point(color = "blue" )+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(
    x = "Fitted Values",
    y = "Standardized Residuals",
  )
dev.off()
ncvTest(model.ace)
```

### Test for normality

```{r echo  = TRUE, eval = TRUE}
shapiro.test(resid(model.ace))
pqq<-ggplot(data.frame(y=rstandard(mod4)), aes(sample = y))+
  stat_qq(color="blue")+
  stat_qq_line(color="red")+
  labs(
    x="Theoretical Quantiles",
    y="Standardized Residuals"
  )
pdf("images/qqplotnp.pdf")
pqq
dev.off()
```

### Multicollinearity

```{r echo = TRUE, eval = TRUE}
library(car)
vif(model.ace)
```

## Heavy Tail Analysis


```{r echo = TRUE, eval = TRUE}
# install.packages("devtools")
# devtools::install_github("faosorios/heavy")
library(heavy)

## base model
mod.heavy1 <- heavyLm(NFCR2019~.-RL2019-RQ2019-Country, data = db19noNA, family = Student(df = 1))
summary(mod.heavy1)

##
mod.heavy2 <- heavyLm(NFCR2019~ yeo.johnson(ARR2019, 0) + WES2019 + yeo.johnson(PV2019, 
    1.34) + yeo.johnson(VA2019, 2), data = db19noNA, family = Student(df = 1))
summary(mod.heavy2)

mod.heavy3 <- heavyLm(NFCR2019~ yeo.johnson(ARR2019, 0) + WES2019 + PV2019 + 
    VA2019, data = db19noNA, family = Student(df = 1))
summary(mod.heavy3)

mod.heavy4 <- heavyLm(NFCR2019~  yeo.johnson(CPI2019, 0.5) + yeo.johnson(ARR2019, 
    0) + WES2019 + PV2019 + VA2019 + RGDP2019-1, data = db19noNA, family = Student(df = 1))
summary(mod.heavy4)

mod.heavy5 <- heavyLm(NFCR2019 ~ yeo.johnson(ARR2019, 
    0) + WES2019 + PV2019 + VA2019 + RGDP2019, data = db19noNA, family = Student(df = 1))
summary(mod.heavy5)

mod.heavy6 <- heavyLm(NFCR2019 ~ yeo.johnson(ARR2019, 
    0) + WES2019 + PV2019 + VA2019 + RGDP2019, data = db19noNA, family = Cauchy())
summary(mod.heavy6)
## going with mod4
plot(y= resid(mod.heavy4), x=fitted(mod.heavy4))
abline(h=0)
mean(resid(mod.heavy4))





library(MASS)
summary(rlm(NFCR2019 ~ yeo.johnson(ARR2019, 
    0) + WES2019 + PV2019 + VA2019 + RGDP2019, data = db19noNA))
```
# Cauchy Errors

```{r echo =  TRUE,eval = TRUE, fig.height = 4}
pdf("images/cauchy.pdf")
par(mfrow=c(1,2))
hist(resid(mod4), freq = FALSE, main = "", xlab=  "Residuals", col="seagreen",
     xlim = c(-1.2,1.2), ylim = c(0,1.4))
x <- seq(-1,1, length = 1e5)
curve(dcauchy(x, 0, 10^-.6), add=TRUE, col = "red", lty = 2, lwd=2)

hist(resid(model.ace), freq = FALSE, main = "", xlab=  "Residuals", col="cyan",
     xlim = c(-1.2,1.2), ylim = c(0,1.4))
curve(dcauchy(x, 0, 10^-.6), add=TRUE, col = "red", lty = 2, lwd=2)
dev.off()


ks.test(resid(mod4), pcauchy, 0, 10^-.6)
ks.test(resid(model.ace), pcauchy, 0, 10^-.6)
```





=======
---
title: "Analysis3"
author: "Arkajyoti Bhattacharjee"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Read and create databases for analysis

```{r echo = TRUE,eval = FALSE}
database <- read.table("database.csv", header = TRUE, sep = ",")
library(tidyverse)
database <- database %>%
  mutate(RGDP2019 = (GDP2019-GDP2018)/GDP2018)
db19 <- database %>%
  select(matches('country|2019')) # add RGDP, rate of change in GDP from 2018-2019
db19 <- select(db19, -GDP2019) # drop GDP2019 
# formatting NFCR column
db19[, "NFCR2019"] <- sapply(db19[,"NFCR2019"], function (x) gsub('%', '', x))
db19[,"NFCR2019"] <- as.numeric(db19[,"NFCR2019"])
#check the number of NAs per column
apply(is.na(db19), 2, sum)
```
# Exploratory Data Analysis

```{r echo = TRUE, eval = TRUE, warning=FALSE}
library(GGally)

## FULL SCATTERPLOT MATRIX TOO SPACIOUS
# ggpairs(db19[, -1], progress = FALSE, 
#         columnLabels = c("NFCR", "CPI", "AML", "ARR", "WES", "GE", "PV", "RQ", 
#                          "RL", "VA", "RGDP")) 

# From the scatterplot matrix, we see that RL and CPI have a high correlation (0.902), along with GE & RL (0.943), GE & RQ (0.9370), and RQ & RL (0.929).
## indicative of multicollinearity
# The distribution of NFCR seems to be heavy-tailed.
# log transforms??
# all are continuous variables
# predictors don't seem to be related to the response much
# We drop RL, RQ(why?--common to CPI, RQ, & GE, Y IS RELATED MORE TO CPI AND GE,
# RQ AND GE ARE SIMILAR INTUTITIVELY)
# EXPLAIN HOW THE RELATIONSHIP IS INTUITIVE?!

## RATHER THAN DOING SCATTERPLOT MATRIX, DO A HEAT MAP FOR SIZE CONSTRAINT OFCOURSE

cor.mat <- round(cor(na.omit(db19[, -1])),3)
library(reshape2)
cor.mat[lower.tri(cor.mat)] <- NA
melted.cor.mat <- melt(cor.mat)

pdf("images/cormatheat.pdf")
ggplot(data = melted.cor.mat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
 scale_fill_viridis_c(option = "turbo", na.value = "white" ,
   limit = c(-1,1), space = "Lab", 
   name="Pearson\nCorrelation") +
  theme_minimal()+ 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.6, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))
dev.off()

pdf("images/scatterplotDropping2.pdf")
ggpairs(db19[, -c(1, 7, 10)], progress = FALSE, 
        columnLabels = c("NFCR", "CPI", "AML", "ARR", "WES", "PV", "RQ", 
                         "VA", "RGDP"),
        axisLabels = "none")
dev.off()
# OTHER SUMMARY PLOTS
subdb19 <- select(db19, c(GE2019, PV2019, RQ2019, RL2019, VA2019))
#install.packages("reshape2")
library(reshape2)
melted.data <- melt(subdb19)
#View(melted.data)
p1 <- ggplot(data = melted.data, aes(x=variable, y=value))+
  geom_boxplot(aes(fill = variable)) + #violin plot 
  labs(
    x= "Governance Quality"
  )

pdf("images/GQs.pdf")
p1
dev.off()


p2 <- ggplot(data = db19, aes(x=NFCR2019))+
  geom_histogram(aes(y=..density..), fill = "magenta")+
  geom_density(color="red")
p3 <- ggplot(data = db19, aes(x=CPI2019))+
  geom_histogram(aes(y=..density..), fill = "seagreen")+
  geom_density(color="red")
p4 <- ggplot(data = db19, aes(x=AML2019))+
  geom_histogram(aes(y=..density..), fill = "orange")+
  geom_density(color="red")
p5 <- ggplot(data = db19, aes(x=ARR2019))+
  geom_histogram(aes(y=..density..), fill = "blue")+
  geom_density(color="red")+
  theme(axis.text.x = element_blank())
p6 <- ggplot(data = db19, aes(x=RGDP2019))+
  geom_histogram(aes(y=..density..), fill = "purple")+
  geom_density(color="red")
p7 <- ggplot(data = db19, aes(x=WES2019))+
  geom_histogram(aes(y=..density..), fill = "cyan")+
  geom_density(color="red")

# install.packages("patchwork")
library(patchwork)
pdf("images/hists.pdf")
(p2 +p3+p4)/(p6 + p5 +p7)
dev.off()
```

# Methods and Model Building

## Naive Model

```{r echo =TRUE, eval =TRUE}
model.naive <- lm(NFCR2019~CPI2019+AML2019+log(ARR2019)+WES2019+GE2019+PV2019+RQ2019+
                    RL2019+VA2019+RGDP2019, data=db19)
library(car)
vif(model.naive)
summary(model.naive)

model.naive2 <- lm(NFCR2019~CPI2019+AML2019+log(ARR2019)+WES2019+GE2019+PV2019+RQ2019+
                    VA2019+RGDP2019, data=db19)
vif(model.naive2)
summary(model.naive2)

model.naive3 <- lm(NFCR2019~CPI2019+AML2019+log(ARR2019)+WES2019+PV2019+RQ2019+VA2019+
                    RGDP2019, data=db19)
vif(model.naive3)
summary(model.naive3)
```
## Transformation of Predictors

```{r echo = TRUE, EVAL = TRUE}
library(car)
summary(powerTransform(cbind(CPI2019, AML2019, log(ARR2019),  WES2019,
                             PV2019, RQ2019,VA2019, RGDP2019)~1, data = db19,
                       family = 'yjPower'))
mod1 <- lm(NFCR2019~sqrt(CPI2019)+AML2019+log(ARR2019)+  WES2019+
                             PV2019+RQ2019+ VA2019+ RGDP2019, data=db19)

vif(mod1)
summary(mod1)

## EXPLORING ALL SUGGESTED TRANSFORMATIONS--NOT INTERPRETABLE

modx <- lm(NFCR2019~sqrt(CPI2019)+AML2019+log(ARR2019)+  WES2019+
                             I(PV2019^1.33)+RQ2019+ I(VA2019^2)+ RGDP2019, data=db19)
vif(modx)
summary(modx)
```
## Variable Selection

```{r echo = TRUE, EVAL = TRUE}
library(leaps)
(summary_best_subset1<-summary(regsubsets(NFCR2019~yeo.johnson(CPI2019,0.5)+
                                            yeo.johnson(ARR2019,0)+  WES2019+
                             PV2019+RQ2019+ VA2019+ RGDP2019, data=na.omit(db19))))
which.max(summary_best_subset1$adjr2)
## keep log(ARR), WES, PV (note correlated with CPI), VA(note correalted with RQ), RGDP (my choice)
(summary_best_subsetx<-summary(regsubsets(NFCR2019~yeo.johnson(CPI2019,0.5)+
                                            yeo.johnson(ARR2019,0)+  WES2019+
                             yeo.johnson(PV2019,1.33)+RQ2019+ yeo.johnson(VA2019,2)+ RGDP2019, data=na.omit(db19))))
which.max(summary_best_subsetx$adjr2)
## keep log(ARR), WES, PV (note correlated with CPI), VA(note correlated with RQ), RGDP (my choice)

## ARR, WES PV VA
## ARR WES PV RQ modx

## EXPLORING ADJUSTED R^2 FOR DIFFERNET VARIABLE SELECTION MODELS
modx2 <- lm(NFCR2019~log(ARR2019)+  WES2019+
                             I(PV2019^1.33)+RQ2019+ RGDP2019, data=db19)
modx3 <- lm(NFCR2019~log(ARR2019)+  WES2019+
                             PV2019+RQ2019+ RGDP2019, data=db19)
mod12 <- lm(NFCR2019~log(ARR2019)+  WES2019+
                             PV2019+VA2019+ RGDP2019, data=db19)
mod13 <- lm(NFCR2019~log(ARR2019)+  WES2019+
                             PV2019+VA2019, data=db19)
summary(modx2)$adj.r.squared
summary(modx3)$adj.r.squared
summary(mod12)$adj.r.squared # highest
summary(mod13)$adj.r.squared
```
## Transformation of response
```{r echo = TRUE,eval = TRUE}
summary(powerTransform(lm(NFCR2019~yeo.johnson(ARR2019, 0) + WES2019 + 
                            PV2019 + VA2019 + RGDP2019, 
                          data = na.omit(db19)),
                       family = 'yjPower'))
##y^1.61

## NOT INTERPRETABLE -- SO IGNORE
```

```{r echo  =TRUE, eval = TRUE}
NFCR<-yeo.johnson(na.omit(db19)[,"NFCR2019"], 1.61)
ARR<-yeo.johnson(na.omit(db19)[,"ARR2019"], 0)
mod2<-lm(NFCR~ARR+WES2019+PV2019+VA2019+RGDP2019, data = na.omit(db19))
summary(mod2)
vif(mod2)
mod3<-lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = na.omit(db19))
summary(mod3)
vif(mod3)

##mod 3 more interpretable and has higher adj R^2
```

## Regression Diagnostics

### Outlier analysis

```{r echo = TRUE, eval = TRUE}
plot(cooks.distance(mod3),type="b",pch=18,col="red")
cutoff = 4*mean(cooks.distance(mod3))
abline(h=cutoff,lty=2)
which(cooks.distance(mod3)>cutoff)

db19woOut <- na.omit(db19)[-c(17,24,36,47,51,60,73),]
db19woOut <- db19woOut[-c(8, 69, 96),]
db19woOut <- db19woOut[-c(11),]
ARR<-yeo.johnson(db19woOut[,"ARR2019"], 0)
mod4<- lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut)

plot(cooks.distance(mod4),type="b",pch=18,col="red")
cutoff = 4*mean(cooks.distance(mod3))
abline(h=cutoff,lty=2)
which(cooks.distance(mod4)>cutoff)

which(hatvalues(mod3)>2*mod3$rank/length(hatvalues(mod3)))
db19woOut2 <- na.omit(db19)[-c(3,21, 31,74,88,99,100,107),]
db19woOut2 <- db19woOut2[-c(3, 41, 67, 97),]
db19woOut2 <- db19woOut2[-c(55),]
db19woOut2 <- db19woOut2[-c(94),]
db19woOut2 <- db19woOut2[-c(21, 46, 66),]
db19woOut2 <- db19woOut2[-c(15, 31, 41, 65),]
ARR<-yeo.johnson(db19woOut2[,"ARR2019"], 0)
mod5<- lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut2)
ncvTest(mod5)
which(hatvalues(mod5)>2*mod5$rank/length(hatvalues(mod5)))




which(abs(rstandard(mod3))>3)
# 24 51 73 
db19woOut3 <- na.omit(db19)[-c(24, 51, 73),]
ARR<-yeo.johnson(db19woOut3[,"ARR2019"], 0)
mod6<- lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut3)
ncvTest(mod6)
which(abs(rstandard(mod6))>3)

db19woOut3 <- db19woOut3[-c(17,35,46),]
ARR<-yeo.johnson(db19woOut3[,"ARR2019"], 0)
mod6<- lm(NFCR2019~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut3)
ncvTest(mod6)
which(abs(rstandard(mod6))>3)

db19woOut3 <- db19woOut3[-c(70),]
ARR<-yeo.johnson(db19woOut3[,"ARR2019"], 0)
mod6<- lm(yeo.johnson(NFCR2019,0)~ARR+WES2019+PV2019+VA2019+RGDP2019, data = db19woOut3)
ncvTest(mod6)
which(abs(rstandard(mod6))>3)

plev1 <- ggplot(data.frame(x=1:length(hatvalues(mod3)),y = hatvalues(mod3)),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Leverage"
  )+
  geom_hline(yintercept = 3*mod3$rank/length(hatvalues(mod3)),
             color = "red", linetype = "dashed")

# pcook1 <- ggplot(data.frame(x=1:length(cooks.distance(mod3)),y = cooks.distance(mod3)),
#                         aes(x=x, y=y))+
#   geom_point()+
#  geom_line(color = "blue")+
#   labs(
#     x = "Data point",
#     y = "Cook's Distance"
#   )+
#   geom_hline(yintercept = 0.5,
#              color = "red", linetype = "dashed")
prstud1 <- ggplot(data.frame(x=1:length(rstudent(mod3)),y = abs(rstudent(mod3))),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Absolute Studentized Residuals"
  )+
  geom_hline(yintercept = 3,
             color = "red", linetype = "dashed")


plev2 <- ggplot(data.frame(x=1:length(hatvalues(mod4)),y = hatvalues(mod4)),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Leverage"
  )+
  geom_hline(yintercept = 3*mod4$rank/length(hatvalues(mod4)),
             color = "red", linetype = "dashed")

# pcook2 <- ggplot(data.frame(x=1:length(cooks.distance(mod4)),y = cooks.distance(mod4)),
#                         aes(x=x, y=y))+
#   geom_point()+
#  geom_line(color = "blue")+
#   labs(
#     x = "Data point",
#     y = "Cook's Distance"
#   )+
#   geom_hline(yintercept = 2*mean(cooks.distance(mod4)),
#              color = "red", linetype = "dashed")
prstud2 <- ggplot(data.frame(x=1:length(rstudent(mod4)),y = abs(rstudent(mod4))),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Absolute Studentized Residuals"
  )+
  geom_hline(yintercept = 3,
             color = "red", linetype = "dashed")

library(patchwork)
pdf("images/outlier.pdf")
(plev1+plev2)/(prstud1+prstud2)
dev.off()
```

### Test for homoscedasticity

```{r echo  = TRUE, eval = TRUE}
pdf("images/homopara.pdf")
ggplot(data.frame(x=fitted(mod4), y = rstandard(mod4)), aes(x=x,y = y))+
  geom_point(color = "blue" )+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(
    x = "Fitted Values",
    y = "Standardized Residuals",
  )
dev.off()
ncvTest(mod4)
```

### Test for normality

```{r echo  = TRUE, eval = TRUE}
shapiro.test(resid(mod4))
pqq<-ggplot(data.frame(y=rstandard(mod4)), aes(sample = y))+
  stat_qq(color="blue")+
  stat_qq_line(color="red")+
  labs(
    x="Theoretical Quantiles",
    y="Standardized Residuals"
  )
pdf("images/qqplot.pdf")
pqq
dev.off()
```

### Multicollinearity

```{r echo = TRUE, eval = TRUE}
library(car)
vif(mod4)
```


# Alternating Conditional Expectation

## ACE Algorithm

```{r echo = TRUE,eval = TRUE}
#install.packages("acepack")
library(acepack)
db19noNA <- na.omit(db19)
ACE <- ace(y = db19noNA[, 2], x = as.matrix(db19noNA[, -c(1, 2)]))
ACEdf<-cbind.data.frame(NFCR2019=ACE$ty, ACE$tx) 
model.ace <- lm(NFCR2019~., data = ACEdf)
summary(model.ace)


library(ggplot2)
p1 <- ggplot(data = data.frame(ACE$y, ACE$ty), aes(x=ACE$y, y = ACE$ty)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "NFCR2019",
    y = "Transformed"
  )
p2 <- ggplot(data = data.frame(x=ACE$x[1, ], y=ACE$tx[, 1]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "CPI2019",
    y = "Transformed"
  )
p3 <- ggplot(data = data.frame(x=ACE$x[2, ], y=ACE$tx[, 2]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "AML2019",
    y = "Transformed"
  )
p4 <- ggplot(data = data.frame(x=ACE$x[3, ], y=ACE$tx[, 3]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "ARR2019",
    y = "Transformed"
  )
p5 <- ggplot(data = data.frame(x=ACE$x[4, ], y=ACE$tx[, 4]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "WES2019",
    y = "Transformed"
  )
p6 <- ggplot(data = data.frame(x=ACE$x[5, ], y=ACE$tx[, 5]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "GE2019",
    y = "Transformed"
  )
p7 <- ggplot(data = data.frame(x=ACE$x[6, ], y=ACE$tx[, 6]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "PV2019",
    y = "Transformed"
  )
p8 <- ggplot(data = data.frame(x=ACE$x[7, ], y=ACE$tx[, 7]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "RQ2019",
    y = "Transformed"
  )
p9 <- ggplot(data = data.frame(x=ACE$x[8, ], y=ACE$tx[, 8]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "RL2019",
    y = "Transformed"
  )
p10 <- ggplot(data = data.frame(x=ACE$x[9, ], y=ACE$tx[, 9]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "VA2019",
    y = "Transformed"
  )
p11 <- ggplot(data = data.frame(x=ACE$x[10, ], y=ACE$tx[, 10]), aes(x=x, y = y)) +
  geom_line(linetype= "dashed", color= "red")+
  labs(
    x= "RGDP2019",
    y = "Transformed"
  )
```

## Regression Diagnostics

### Outlier analysis

```{r echo = TRUE, eval = TRUE}
db19noNA <- na.omit(db19)
ACE <- ace(y = db19noNA[, 2], x = as.matrix(db19noNA[, -c(1, 2)]))
ACEdf<-cbind.data.frame(NFCR2019=ACE$ty, ACE$tx) 
model.ace <- lm(NFCR2019~., data = ACEdf)


plot(cooks.distance(model.ace),type="b",pch=18,col="red")
cutoff = 4*mean(cooks.distance(model.ace))
abline(h=cutoff,lty=2)
plot(abs(hatvalues(model.ace)), type= "b")
abline(h=3*model.ace$rank/length(hatvalues(model.ace)))
plot(abs(rstandard(model.ace)), type= "b")
abline(h=3)

which(cooks.distance(model.ace)>cutoff)
which(abs(hatvalues(model.ace))>3*model.ace$rank/length(hatvalues(model.ace)))
which(abs(rstandard(model.ace))>3)


ncvTest(model.ace)

db19noNA <- db19noNA[-c(44,49),]
db19noNA <- db19noNA[-c(17),]
db19noNA <- db19noNA[-c(17),]
db19noNA <- db19noNA[-c(69),]
db19noNA <- db19noNA[-c(102),]
db19noNA <- db19noNA[-c(102),]
db19noNA <- db19noNA[-c(83),]
db19noNA <- db19noNA[-c(54),]
db19noNA <- db19noNA[-c(30),]
db19noNA <- db19noNA[-c(54),]

ACE <- ace(y = db19noNA[, 2], x = as.matrix(db19noNA[, -c(1, 2)]))
ACEdf<-cbind.data.frame(NFCR2019=ACE$ty, ACE$tx) 
model.ace <- lm(NFCR2019~., data = ACEdf)
summary(model.ace)$adj.r.squared

plev3 <- ggplot(data.frame(x=1:length(hatvalues(model.ace)),y = hatvalues(model.ace)),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Leverage"
  )+
  geom_hline(yintercept = 3*model.ace$rank/length(hatvalues(model.ace)),
             color = "red", linetype = "dashed")

prstud3 <- ggplot(data.frame(x=1:length(rstudent(model.ace)),y = abs(rstudent(model.ace))),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Absolute Studentized Residuals"
  )+
  geom_hline(yintercept = 3,
             color = "red", linetype = "dashed")


plev4 <- ggplot(data.frame(x=1:length(hatvalues(model.ace)),y = hatvalues(model.ace)),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Leverage"
  )+
  geom_hline(yintercept = 3*mod4$rank/length(hatvalues(mod4)),
             color = "red", linetype = "dashed")

prstud4 <- ggplot(data.frame(x=1:length(rstudent(model.ace)),y = abs(rstudent(model.ace))),
                        aes(x=x, y=y))+
  geom_point()+
 geom_line(color = "blue")+
  labs(
    x = "Data point",
    y = "Absolute Studentized Residuals"
  )+
  geom_hline(yintercept = 3,
             color = "red", linetype = "dashed")

library(patchwork)
pdf("images/outliernp.pdf")
(plev3+plev4)/(prstud3+prstud4)
dev.off()
```

### Test for homoscedasticity

```{r echo  = TRUE, eval = TRUE}
pdf("images/homoparanp.pdf")
ggplot(data.frame(x=fitted(model.ace), y = rstandard(model.ace)), aes(x=x,y = y))+
  geom_point(color = "blue" )+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(
    x = "Fitted Values",
    y = "Standardized Residuals",
  )
dev.off()
ncvTest(model.ace)
```

### Test for normality

```{r echo  = TRUE, eval = TRUE}
shapiro.test(resid(model.ace))
pqq<-ggplot(data.frame(y=rstandard(mod4)), aes(sample = y))+
  stat_qq(color="blue")+
  stat_qq_line(color="red")+
  labs(
    x="Theoretical Quantiles",
    y="Standardized Residuals"
  )
pdf("images/qqplotnp.pdf")
pqq
dev.off()
```

### Multicollinearity

```{r echo = TRUE, eval = TRUE}
library(car)
vif(model.ace)
```

## Heavy Tail Analysis


```{r echo = TRUE, eval = TRUE}
# install.packages("devtools")
# devtools::install_github("faosorios/heavy")
library(heavy)

## base model
mod.heavy1 <- heavyLm(NFCR2019~.-RL2019-RQ2019-Country, data = db19noNA, family = Student(df = 1))
summary(mod.heavy1)

##
mod.heavy2 <- heavyLm(NFCR2019~ yeo.johnson(ARR2019, 0) + WES2019 + yeo.johnson(PV2019, 
    1.34) + yeo.johnson(VA2019, 2), data = db19noNA, family = Student(df = 1))
summary(mod.heavy2)

mod.heavy3 <- heavyLm(NFCR2019~ yeo.johnson(ARR2019, 0) + WES2019 + PV2019 + 
    VA2019, data = db19noNA, family = Student(df = 1))
summary(mod.heavy3)

mod.heavy4 <- heavyLm(NFCR2019~  yeo.johnson(CPI2019, 0.5) + yeo.johnson(ARR2019, 
    0) + WES2019 + PV2019 + VA2019 + RGDP2019-1, data = db19noNA, family = Student(df = 1))
summary(mod.heavy4)

mod.heavy5 <- heavyLm(NFCR2019 ~ yeo.johnson(ARR2019, 
    0) + WES2019 + PV2019 + VA2019 + RGDP2019, data = db19noNA, family = Student(df = 1))
summary(mod.heavy5)

mod.heavy6 <- heavyLm(NFCR2019 ~ yeo.johnson(ARR2019, 
    0) + WES2019 + PV2019 + VA2019 + RGDP2019, data = db19noNA, family = Cauchy())
summary(mod.heavy6)
## going with mod4
plot(y= resid(mod.heavy4), x=fitted(mod.heavy4))
abline(h=0)
mean(resid(mod.heavy4))





library(MASS)
summary(rlm(NFCR2019 ~ yeo.johnson(ARR2019, 
    0) + WES2019 + PV2019 + VA2019 + RGDP2019, data = db19noNA))
```
# Cauchy Errors

```{r echo =  TRUE,eval = TRUE, fig.height = 4}
pdf("images/cauchy.pdf")
par(mfrow=c(1,2))
hist(resid(mod4), freq = FALSE, main = "", xlab=  "Residuals", col="seagreen",
     xlim = c(-1.2,1.2), ylim = c(0,1.4))
x <- seq(-1,1, length = 1e5)
curve(dcauchy(x, 0, 10^-.6), add=TRUE, col = "red", lty = 2, lwd=2)

hist(resid(model.ace), freq = FALSE, main = "", xlab=  "Residuals", col="cyan",
     xlim = c(-1.2,1.2), ylim = c(0,1.4))
curve(dcauchy(x, 0, 10^-.6), add=TRUE, col = "red", lty = 2, lwd=2)
dev.off()


ks.test(resid(mod4), pcauchy, 0, 10^-.6)
ks.test(resid(model.ace), pcauchy, 0, 10^-.6)
```


# Comparison of Models




```{r}

database <- database %>%
  mutate(RGDP2014 = (GDP2014-GDP2013)/GDP2013)


db14 <- database %>%
  select(matches('country|2014')) # add RGDP, rate of change in GDP from 2018-2019
db14 <- select(db14, -GDP2014) # drop GDP2019 


db14[, "NFCR2014"] <- sapply(db14[,"NFCR2014"], function (x) gsub('%', '', x))
db14[,"NFCR2014"] <- as.numeric(db14[,"NFCR2014"])


ARR<-yeo.johnson(na.omit(db14)[,"ARR2014"], 0)
mod3<-lm(NFCR2014~ARR+WES2014+PV2014+VA2014+RGDP2014, data = na.omit(db14))


plot(cooks.distance(mod3),type="b",pch=18,col="red")
N = nrow(na.omit(db14))
k = mod3$rank
cutoff = 4/(N-k)
abline(h=cutoff,lty=2)
which(cooks.distance(mod3)>cutoff)

db14woOut <- na.omit(db14)
ARR<-yeo.johnson(db14woOut[,"ARR2014"], 0)
mod4_2014<- lm(NFCR2014~ARR+WES2014+PV2014+VA2014+RGDP2014, data = db14woOut)


################################################################################

coef_2014=coef(mod4_2014)[-1]

Var_2014=vcov(mod4_2014)[-1,-1]

coef_2019=coef(mod4)[-1]

Var_2019=vcov(mod4)[-1,-1]


n_2014=dim(db14woOut)[1]

n_2019=dim(db19woOut)[1]



n=n_2014+n_2019


coef_2014=as.matrix(coef_2014,4,1)
coef_2019=as.matrix(coef_2019,4,1)




write.csv(data.frame(coef_2019,coef_2014),"Coefs.csv")


Var=((n_2014-1)*Var_2014+(n_2019-1)*Var_2019)/(n_2014+n_2019-2)

T2=t(coef_2019-coef_2014) %*% solve(Var*(1/n_2014+1/n_2019)) %*% (coef_2019-coef_2014)


k=dim(coef_2014)[1]


F_st=(n-k)/(k*(n-1))*T2


p_value=pf(F_st[1][1],k,n-k,lower.tail = FALSE)


D_F=data.frame(n_2019,n_2014,k,T2,F_st,p_value)


write.csv(D_F,"D_F.csv")


```


# World Map


```{r}
rm(list=ls())


library(readxl)
library(tidyverse)
library(xlsx)
library(rvest)
library(magrittr)
library(ggmap)
library(rnaturalearth)
library(rnaturalearthdata)

setwd("D:/OSU Course Materials/6950 - Applied Statistics 2/Project")

Data=read.xlsx("database.xlsx",sheetIndex = 1)


Data <- Data %>%
  mutate(RGDP2019 = (GDP2019-GDP2018)/GDP2018,
         RGDP2014 = (GDP2014-GDP2013)/GDP2013)


Data$name=Data$Country

world <- ne_countries(scale = "medium", returnclass = "sf")

world[which(world$name=="United States"),]$name="United States of America"

DD=world %>% left_join(Data)

#DD= DD %>% filter(name!="Antarctica")

a=ggplot(data = DD,aes(fill=NFCR2019)) +
  geom_sf()+theme_bw()

pdf("Map_deforest.pdf")
a+scale_fill_gradient(low="red", high="yellow")+
  coord_sf(crs = "+proj=laea +lat_0=0 +lon_0=0 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs ")
dev.off()



b=ggplot(data = DD,aes(fill=RGDP2019)) +
  geom_sf()+theme_bw()


pdf("Map_rgdp.pdf")
b+scale_fill_gradient(low="red", high="blue")+
  coord_sf(crs = "+proj=laea +lat_0=0 +lon_0=0 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs ")
dev.off()

```


>>>>>>> c43b93265cfa95892cd7db24d16d57c57f74a13b
